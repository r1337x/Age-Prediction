{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-25 18:43:30.062452: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-25 18:43:39.409395: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-25 18:43:58.200230: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/pdda_lab_user/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-10-25 18:43:58.200384: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/pdda_lab_user/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-10-25 18:43:58.200402: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from keras.models import Sequential,load_model,Model\n",
    "from keras.layers import Conv2D,MaxPool2D,Dense,Dropout,BatchNormalization,Flatten,Input\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/UTKFace\"\n",
    "images = []\n",
    "age = []\n",
    "gender = []\n",
    "for img in os.listdir(path):\n",
    "  ages = img.split(\"_\")[0] #The first value before the _ is age\n",
    "  img = cv2.imread(str(path)+\"/\"+str(img))\n",
    "  img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "  images.append(np.array(img))\n",
    "  age.append(np.array(ages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = np.array(age,dtype=np.int64)\n",
    "images = np.array(images)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_age, x_test_age, y_train_age, y_test_age = train_test_split(images, age, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-25 19:02:08.050230: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-25 19:02:32.019023: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10787 MB memory:  -> device: 0, name: Tesla K80, pci bus id: 0001:00:00.0, compute capability: 3.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 198, 198, 128)     3584      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 98, 98, 128)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 96, 96, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 47, 47, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 45, 45, 256)       295168    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 22, 22, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 20, 20, 512)       1180160   \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 9, 9, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 41472)             0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 41472)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               21234176  \n",
      "                                                                 \n",
      " age (Dense)                 (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,861,185\n",
      "Trainable params: 22,861,185\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-25 19:03:10.176406: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8400\n",
      "2022-10-25 19:03:58.357174: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "556/556 [==============================] - 264s 302ms/step - loss: 62642.6484 - mae: 25.6811 - val_loss: 254.8404 - val_mae: 12.8334\n",
      "Epoch 2/50\n",
      "556/556 [==============================] - 164s 294ms/step - loss: 235.6303 - mae: 11.7324 - val_loss: 213.6995 - val_mae: 10.7306\n",
      "Epoch 3/50\n",
      "556/556 [==============================] - 164s 294ms/step - loss: 205.2813 - mae: 10.9601 - val_loss: 171.3535 - val_mae: 9.9513\n",
      "Epoch 4/50\n",
      "556/556 [==============================] - 164s 295ms/step - loss: 174.5600 - mae: 10.0223 - val_loss: 147.5504 - val_mae: 8.9191\n",
      "Epoch 5/50\n",
      "556/556 [==============================] - 164s 295ms/step - loss: 149.0925 - mae: 9.2242 - val_loss: 155.8577 - val_mae: 9.1276\n",
      "Epoch 6/50\n",
      "556/556 [==============================] - 164s 294ms/step - loss: 140.6497 - mae: 8.9129 - val_loss: 122.9453 - val_mae: 8.2118\n",
      "Epoch 7/50\n",
      "556/556 [==============================] - 164s 294ms/step - loss: 130.2682 - mae: 8.5735 - val_loss: 151.5500 - val_mae: 9.8527\n",
      "Epoch 8/50\n",
      "556/556 [==============================] - 163s 293ms/step - loss: 481.9763 - mae: 13.5532 - val_loss: 425.8915 - val_mae: 15.6536\n",
      "Epoch 9/50\n",
      "556/556 [==============================] - 163s 293ms/step - loss: 539.4193 - mae: 15.1598 - val_loss: 276.9787 - val_mae: 13.6436\n",
      "Epoch 10/50\n",
      "556/556 [==============================] - 163s 293ms/step - loss: 243.4204 - mae: 11.8050 - val_loss: 205.3534 - val_mae: 10.6083\n",
      "Epoch 11/50\n",
      "556/556 [==============================] - 163s 293ms/step - loss: 214.3905 - mae: 11.0365 - val_loss: 184.8699 - val_mae: 10.2532\n",
      "Epoch 12/50\n",
      "556/556 [==============================] - 163s 293ms/step - loss: 190.2545 - mae: 10.2357 - val_loss: 147.7097 - val_mae: 8.8793\n",
      "Epoch 13/50\n",
      "556/556 [==============================] - 163s 293ms/step - loss: 169.5754 - mae: 9.6937 - val_loss: 220.5051 - val_mae: 10.7952\n",
      "Epoch 14/50\n",
      "556/556 [==============================] - 163s 293ms/step - loss: 156.9271 - mae: 9.3078 - val_loss: 150.1769 - val_mae: 8.8317\n",
      "Epoch 15/50\n",
      "556/556 [==============================] - 163s 293ms/step - loss: 144.1214 - mae: 8.8902 - val_loss: 119.5445 - val_mae: 7.9860\n",
      "Epoch 16/50\n",
      "556/556 [==============================] - 163s 293ms/step - loss: 135.4745 - mae: 8.6332 - val_loss: 108.5741 - val_mae: 7.7543\n",
      "Epoch 17/50\n",
      "556/556 [==============================] - 163s 293ms/step - loss: 132.8874 - mae: 8.5365 - val_loss: 132.6749 - val_mae: 8.3362\n",
      "Epoch 18/50\n",
      "556/556 [==============================] - 163s 293ms/step - loss: 122.0939 - mae: 8.1905 - val_loss: 120.1604 - val_mae: 8.0018\n",
      "Epoch 19/50\n",
      "556/556 [==============================] - 163s 293ms/step - loss: 131.4281 - mae: 8.4750 - val_loss: 107.5448 - val_mae: 7.6879\n",
      "Epoch 20/50\n",
      "556/556 [==============================] - 163s 293ms/step - loss: 123.7338 - mae: 8.2346 - val_loss: 116.0047 - val_mae: 7.6614\n",
      "Epoch 21/50\n",
      "556/556 [==============================] - 163s 293ms/step - loss: 116.3290 - mae: 7.9609 - val_loss: 153.4157 - val_mae: 8.8173\n",
      "Epoch 22/50\n",
      "556/556 [==============================] - 162s 292ms/step - loss: 109.6359 - mae: 7.7490 - val_loss: 150.1201 - val_mae: 8.5574\n",
      "Epoch 23/50\n",
      "556/556 [==============================] - 162s 292ms/step - loss: 111.1726 - mae: 7.7691 - val_loss: 105.8954 - val_mae: 7.5940\n",
      "Epoch 24/50\n",
      "556/556 [==============================] - 162s 292ms/step - loss: 99.7563 - mae: 7.3949 - val_loss: 90.8647 - val_mae: 6.9598\n",
      "Epoch 25/50\n",
      "556/556 [==============================] - 162s 292ms/step - loss: 106.9377 - mae: 7.6438 - val_loss: 102.3851 - val_mae: 7.5735\n",
      "Epoch 26/50\n",
      "556/556 [==============================] - 162s 291ms/step - loss: 95.3178 - mae: 7.2203 - val_loss: 89.8375 - val_mae: 6.9651\n",
      "Epoch 27/50\n",
      "556/556 [==============================] - 162s 291ms/step - loss: 88.7098 - mae: 6.9738 - val_loss: 94.6296 - val_mae: 7.1887\n",
      "Epoch 28/50\n",
      "556/556 [==============================] - 161s 289ms/step - loss: 129.9670 - mae: 8.2395 - val_loss: 95.6083 - val_mae: 7.1366\n",
      "Epoch 29/50\n",
      "556/556 [==============================] - 160s 289ms/step - loss: 82.5808 - mae: 6.7634 - val_loss: 93.7407 - val_mae: 7.0382\n",
      "Epoch 30/50\n",
      "556/556 [==============================] - 161s 289ms/step - loss: 78.2768 - mae: 6.5802 - val_loss: 92.7005 - val_mae: 6.9384\n",
      "Epoch 31/50\n",
      "556/556 [==============================] - 160s 288ms/step - loss: 76.3477 - mae: 6.4916 - val_loss: 84.4389 - val_mae: 6.6634\n",
      "Epoch 32/50\n",
      "556/556 [==============================] - 160s 288ms/step - loss: 73.7321 - mae: 6.3763 - val_loss: 85.9542 - val_mae: 6.5715\n",
      "Epoch 33/50\n",
      "556/556 [==============================] - 160s 287ms/step - loss: 71.9661 - mae: 6.3036 - val_loss: 96.2562 - val_mae: 7.0236\n",
      "Epoch 34/50\n",
      "556/556 [==============================] - 160s 287ms/step - loss: 69.0873 - mae: 6.1826 - val_loss: 91.7105 - val_mae: 6.7466\n",
      "Epoch 35/50\n",
      "556/556 [==============================] - 160s 287ms/step - loss: 66.4733 - mae: 6.1039 - val_loss: 82.8714 - val_mae: 6.5683\n",
      "Epoch 36/50\n",
      "556/556 [==============================] - 160s 287ms/step - loss: 68.0373 - mae: 6.1429 - val_loss: 84.4196 - val_mae: 6.5391\n",
      "Epoch 37/50\n",
      "556/556 [==============================] - 160s 287ms/step - loss: 60.9018 - mae: 5.8327 - val_loss: 84.1982 - val_mae: 6.4698\n",
      "Epoch 38/50\n",
      "556/556 [==============================] - 160s 287ms/step - loss: 58.0478 - mae: 5.6852 - val_loss: 86.8619 - val_mae: 6.6548\n",
      "Epoch 39/50\n",
      "556/556 [==============================] - 159s 287ms/step - loss: 56.1223 - mae: 5.5840 - val_loss: 87.7505 - val_mae: 6.6018\n",
      "Epoch 40/50\n",
      "556/556 [==============================] - 159s 286ms/step - loss: 58.8781 - mae: 5.6788 - val_loss: 91.9677 - val_mae: 7.0348\n",
      "Epoch 41/50\n",
      "556/556 [==============================] - 159s 286ms/step - loss: 51.8573 - mae: 5.3986 - val_loss: 83.5828 - val_mae: 6.8041\n",
      "Epoch 42/50\n",
      "556/556 [==============================] - 159s 286ms/step - loss: 49.7086 - mae: 5.2779 - val_loss: 85.8972 - val_mae: 6.6970\n",
      "Epoch 43/50\n",
      "556/556 [==============================] - 159s 286ms/step - loss: 51.1037 - mae: 5.3406 - val_loss: 86.4508 - val_mae: 6.5859\n",
      "Epoch 44/50\n",
      "556/556 [==============================] - 159s 286ms/step - loss: 46.6539 - mae: 5.1143 - val_loss: 83.3592 - val_mae: 6.6179\n",
      "Epoch 45/50\n",
      "556/556 [==============================] - 159s 285ms/step - loss: 44.7406 - mae: 5.0335 - val_loss: 82.3839 - val_mae: 6.5838\n",
      "Epoch 46/50\n",
      "556/556 [==============================] - 159s 285ms/step - loss: 48.2599 - mae: 5.1737 - val_loss: 87.1027 - val_mae: 6.7121\n",
      "Epoch 47/50\n",
      "556/556 [==============================] - 163s 293ms/step - loss: 42.1481 - mae: 4.8690 - val_loss: 85.0736 - val_mae: 6.5612\n",
      "Epoch 48/50\n",
      "556/556 [==============================] - 159s 285ms/step - loss: 40.5614 - mae: 4.7734 - val_loss: 85.8731 - val_mae: 6.4952\n",
      "Epoch 49/50\n",
      "556/556 [==============================] - 159s 285ms/step - loss: 39.7252 - mae: 4.7242 - val_loss: 86.3121 - val_mae: 6.9347\n",
      "Epoch 50/50\n",
      "556/556 [==============================] - 159s 285ms/step - loss: 36.7086 - mae: 4.5886 - val_loss: 84.8101 - val_mae: 6.5212\n"
     ]
    }
   ],
   "source": [
    "age_model = Sequential()\n",
    "age_model.add(Conv2D(128, kernel_size=3, activation='relu', input_shape=(200,200,3)))\n",
    "age_model.add(MaxPool2D(pool_size=3, strides=2))\n",
    "\n",
    "age_model.add(Conv2D(128, kernel_size=3, activation='relu'))\n",
    "age_model.add(MaxPool2D(pool_size=3, strides=2))\n",
    "              \n",
    "age_model.add(Conv2D(256, kernel_size=3, activation='relu'))\n",
    "age_model.add(MaxPool2D(pool_size=3, strides=2))\n",
    "\n",
    "age_model.add(Conv2D(512, kernel_size=3, activation='relu'))\n",
    "age_model.add(MaxPool2D(pool_size=3, strides=2))\n",
    "\n",
    "age_model.add(Flatten())\n",
    "age_model.add(Dropout(0.2))\n",
    "age_model.add(Dense(512, activation='relu'))\n",
    "\n",
    "# Use 1 node and linear activation as this isn't a classification problem\n",
    "age_model.add(Dense(1, activation='linear', name='age'))\n",
    "              \n",
    "age_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "print(age_model.summary())              \n",
    "                           \n",
    "history_age = age_model.fit(x_train_age, y_train_age,\n",
    "                        validation_data=(x_test_age, y_test_age), epochs=50)\n",
    "\n",
    "age_model.save('age_model_50epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186/186 [==============================] - 15s 82ms/step\n",
      "Accuracy =  0.02986333727011979\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "#Test the model\n",
    "my_model = load_model('age_model_50epochs.h5', compile=False)\n",
    "\n",
    "\n",
    "predictions = my_model.predict(x_test_age)\n",
    "y_pred = (predictions>= 0.5).astype(int)[:,0]\n",
    "\n",
    "from sklearn import metrics\n",
    "print (\"Accuracy = \", metrics.accuracy_score(y_test_age, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR:0@10827.227] global /io/opencv/modules/core/src/persistence.cpp (505) open Can't open file: 'haarcascades_models/haarcascade_frontalface_default.xml' in read mode\n"
     ]
    }
   ],
   "source": [
    "face_classifier=cv2.CascadeClassifier('haarcascades_models/haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_model = load_model('age_model_50epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret,frame=cap.read()\n",
    "    labels=[]\n",
    "    \n",
    "    gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    faces=face_classifier.detectMultiScale(gray,1.3,5)\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        roi_gray=gray[y:y+h,x:x+w]\n",
    "        roi_gray=cv2.resize(roi_gray,(48,48),interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        #Get image ready for prediction\n",
    "        roi=roi_gray.astype('float')/255.0  #Scale\n",
    "        roi=img_to_array(roi)\n",
    "        roi=np.expand_dims(roi,axis=0)  #Expand dims to get it ready for prediction (1, 48, 48, 1)\n",
    "        \n",
    "        roi_color=frame[y:y+h,x:x+w]\n",
    "        roi_color=cv2.resize(roi_color,(200,200),interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        age_predict = age_model.predict(np.array(roi_color).reshape(-1,200,200,3))\n",
    "        age = round(age_predict[0,0])\n",
    "        age_label_position=(x+h,y+h)\n",
    "        cv2.putText(frame,\"Age=\"+str(age),age_label_position,cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),2)\n",
    "        \n",
    "   \n",
    "    cv2.imshow('Emotion Detector', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.14 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
